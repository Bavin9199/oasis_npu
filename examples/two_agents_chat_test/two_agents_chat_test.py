import asyncio
import os
import re
import logging
from openai import OpenAI
import pandas as pd
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ================================================================
# 1. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå¯æ¢æˆ OpenRouterï¼‰
# ================================================================
os.environ["OPENROUTER_API_KEY"] = "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"
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.environ["OPENROUTER_API_KEY"]
)
model_type = "gpt-4o-mini"

agent_desc_path = "E:\\NPU\\P0\\OASIS\\oasis_npu\\character profile\\user_descriptions.csv"
agent_desc = pd.read_csv(agent_desc_path)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log", encoding="utf-8"),  # æŒ‡å®š UTF-8
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯
    ]
)
logging.getLogger("httpx").setLevel(logging.WARNING)

# å±è”½ openai / openrouter çš„ info æ—¥å¿—
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("openrouter").setLevel(logging.WARNING)

# ================================================================
# 2. ç®€å• Agent ç±»
# ================================================================
class SimpleAgent:
    def __init__(self, id, name, dynamic_desc=""):
        self.id = id
        self.name = name
        self.dynamic_desc = dynamic_desc

    
    async def respond(self, message, agent_prompt):
        """
        è¿™é‡Œæ˜¯æ¯è½®ç”Ÿæˆ prompt çš„åœ°æ–¹ã€‚
        ä½ å¯ä»¥ç”¨ dynamic_desc + ä¸Šä¸€æ¡æ¶ˆæ¯ message ç»„åˆ promptã€‚
        """
        selected_type = "llm"
        if selected_type == "llm":
            dynamic_desc = _select_prompt_by_llm(agent_prompt, message)
        elif selected_type == "static_only":
            dynamic_desc = _select_prompt_by_static_only(agent_prompt)
        elif selected_type == "RAG":
            dynamic_desc = _select_prompt_by_rag(agent_prompt, message)
        else:
            dynamic_desc = agent_prompt
        # ==========================
        # ---- æ„é€  Prompt ----
        # ==========================
        agent_desc = dynamic_desc.split("# SELF-DESCRIPTION")[1].split("# RESPONSE METHOD")[0].strip()
        #print(agent_desc)
        prompt = f"""
        You are a social media user named {self.name}.
        Your dynamic profile is: {agent_desc}

        You have just received the following message:
        "{message}"

        1. ä½¿ç”¨ç¬¬ä¸€äººç§°ã€å£è¯­åŒ–çš„è¯­æ°”
        2. ç»“æ„è¦æ•£ä¹±ï¼Œæ®µè½è¿‡åº¦è¦è‡ªç„¶ï¼Œä¸è¦ä½¿ç”¨ â€œé¦–å…ˆã€å…¶æ¬¡â€ ç­‰è¿‡æ¸¡è¯
        3. å¯ä»¥ä¸¾çœŸå®ä¾‹å­ / æ¯”å–» / ç©æ¢—ï¼Œå¢åŠ çœŸå®æ€§ï¼Œä½†ä¸è¦è¿‡äºé¢‘ç¹
        4. é€»è¾‘ä¸è¦å¤ªæ¸…æ™°ï¼Œå¯ä»¥é€‚å½“å‡ºç°é€»è¾‘ä¸é€šã€æ€ç»´è·³è·ƒå’Œè½¬æŠ˜
        5. ä¸è¦ä½¿ç”¨è¿‡äºä¸“ä¸šçš„è¯æ±‡ï¼Œæ ‡ç‚¹ç¬¦å·çš„è¿ç”¨ä¹Ÿä¸è¦å¤ªæ ‡å‡†

        Based on your dynamic profile and the received message, generate a short reply (within 50 words).
        Your reply must be in Chinese.
        """
        # ==========================
        # ---- è°ƒç”¨æ¨¡å‹ ----
        # ==========================
        #print(prompt)
        response = client.chat.completions.create(
            model=model_type,
            messages=[{"role": "user", "content": prompt}]
        )
        # è·å–ç”Ÿæˆå†…å®¹
        reply = response.choices[0].message.content.strip()
        critique = critique_ai_style(reply)
        id = self.id
        final_reply = rewrite_with_critic(id, reply, critique)
        return final_reply

def critique_ai_style(draft_reply):
    """
    è°ƒç”¨å¤§æ¨¡å‹ Bï¼Œå¯¹è‰ç¨¿è¿›è¡Œ AI å‘³è¯„ä»·å’Œæå‡ºä¿®æ”¹å»ºè®®
    """
    critique_points = """
            {
                "ç»´åº¦": "è¯­è¨€æ˜¯å¦è¿‡äºæ­£å¼ã€ç”Ÿç¡¬ã€ä¹¦é¢åŒ–",
                "å«ä¹‰": "AI å®¹æ˜“å†™æˆè®ºæ–‡å¼ã€å®¢æœå¼ã€è¯´æ˜æ–‡å¼è¯­æ°”ï¼Œè€Œä¸æ˜¯è‡ªç„¶å£è¯­ã€‚",
                "ç—‡çŠ¶": [
                    "å¥å­å¤ªå®Œæ•´ï¼Œæ²¡æœ‰å£è¯­åœé¡¿",
                    "ç”¨è¯åä¹¦é¢ï¼Œå¦‚â€˜ç„¶è€Œâ€™ã€â€˜æ­¤å¤–â€™ã€â€˜å› æ­¤â€™ã€â€˜å€¼å¾—æ³¨æ„çš„æ˜¯â€™",
                    "ç¼ºå°‘å£è¯­ä¹ æƒ¯ç”¨è¯­ï¼Œå¦‚â€˜æˆ‘é ã€å‘ƒã€å…¶å®ã€æ„Ÿè§‰å§ã€è¯´å®è¯â€™"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "åŠ å…¥å£è¯­è¡¨è¾¾ï¼Œå¦‚â€˜è¯´çœŸçš„â€¦â€™ã€â€˜æˆ‘è§‰å¾—â€¦â€™",
                    "å…è®¸å¥å­ä¸å®Œæ•´ã€æœ‰åœé¡¿å’Œè½¬æŠ˜",
                    "å‡å°‘ä¹¦é¢è¿æ¥è¯ï¼Œæ”¹æˆå£è¯­åŒ–â€˜ç„¶åå‘¢â€¦â€™ã€â€˜ç»“æœå°±â€¦â€™"
                ]
            },
            {
                "ç»´åº¦": "é€»è¾‘æ˜¯å¦è¿‡åº¦å®Œæ•´ã€çº¿æ€§ã€åƒæœºæ¢°æ¨æ¼”",
                "å«ä¹‰": "AI æ–‡æœ¬é€šå¸¸é€»è¾‘è¿‡äºå®Œæ•´ã€çº¿æ€§ï¼Œè€ŒçœŸå®å¯¹è¯ä¼šè·³è·ƒã€å¸¦æƒ…ç»ªã€‚",
                "ç—‡çŠ¶": [
                    "æ®µè½æ˜æ˜¾æŒ‰ç»“æ„æ’åˆ—ï¼Œåƒå†™ä½œæ–‡",
                    "æ¯å¥è¯éƒ½æŒ‰â€˜åŸå› â†’ç»“è®ºâ†’è¡¥å……â€™æ¨¡å¼",
                    "æ²¡æœ‰æ€è·¯ä¸­æ–­ã€çŠ¹è±«æˆ–ä¸´æ—¶è½¬å‘"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "åŠ å…¥è‡ªç„¶æ€ç»´è·³è·ƒï¼Œå¦‚â€˜æ¬¸ä¸å¯¹ï¼Œæˆ‘æƒ³äº†æƒ³â€¦â€™",
                    "å…è®¸é€»è¾‘ä¸å®Œæ•´ï¼Œå¦‚â€˜æˆ‘ä¹Ÿä¸å¤ªç¡®å®šï¼Œä½†â€¦â€™",
                    "åŠ å…¥ä¸´æ—¶è‡ªæˆ‘çº æ­£æˆ–çŠ¹è±«è¡¨è¾¾"
                ]
            },
            {
                "ç»´åº¦": "è¡¨è¾¾æ˜¯å¦ä¸å¤Ÿè‡ªç„¶ã€ç¼ºä¹äººç±»è¯­æ°”å˜åŒ–",
                "å«ä¹‰": "AI è¯­æ°”å¸¸ç»Ÿä¸€ï¼Œç¼ºå°‘è‡ªç„¶é«˜ä½èµ·ä¼ã€‚",
                "ç—‡çŠ¶": [
                    "ç¼ºä¹æ„Ÿå¹ã€çŠ¹è±«ã€åæ§½",
                    "å…¨ç¯‡è¯­æ°”ä¸€è‡´ï¼Œè¦ä¹ˆå¤ªå¼€å¿ƒï¼Œè¦ä¹ˆå¤ªä¸­æ€§",
                    "ç¼ºå°‘è‡ªç„¶è¯­è°ƒè¯ï¼Œå¦‚â€˜æ¬¸ã€å“å‘€ã€ç­‰ä¼šå„¿ã€ç®—äº†â€™"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "åŠ å…¥è¯­æ°”è¯ã€å£å¤´ç¦…ã€ååº”è¯",
                    "å…è®¸æƒ…ç»ªé«˜ä½å˜åŒ–ï¼Œæ¯”å¦‚çªç„¶å…´å¥‹æˆ–æ³„æ°”",
                    "æ‰“ç ´å¹³ç›´è¯­è°ƒï¼Œå¦‚â€˜æˆ‘å½“æ—¶æ•´ä¸ªäººéƒ½æ„£ä½äº†â€™"
                ]
            },
            {
                "ç»´åº¦": "æ˜¯å¦å­˜åœ¨è¿‡å¤šçš„èµåŒã€è¿åˆã€ç¼ºä¹ç‹¬ç«‹åˆ¤æ–­",
                "å«ä¹‰": "AI è¿‡åº¦è®¤å¯å¯¹æ–¹è§‚ç‚¹ï¼Œæ— æ³•æ ¹æ®è‡ªå·±ç‰¹å¾æå‡ºæ–°çš„è§‚ç‚¹ã€‚",
                "ç—‡çŠ¶": [
                    "åŠ¨ä¸åŠ¨è¯´â€˜ä½ è¯´å¾—å¾ˆå¯¹â€™",
                    "æ— è®ºå¯¹æ–¹è¯´ä»€ä¹ˆéƒ½é™„å’Œ",
                    "æ²¡æœ‰è‡ªå·±çš„åˆ¤æ–­ï¼Œåªæ˜¯â€˜ä½ è§‰å¾—æ€æ ·å°±æ€æ ·â€™"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "å‡å°‘è‡ªåŠ¨é™„å’Œï¼Œé€‚å½“è¡¨è¾¾ä¸åŒè§‚ç‚¹",
                    "åŠ å…¥çœŸå®å¯¹è¯é£æ ¼ï¼Œå¦‚â€˜æˆ‘ä¸å®Œå…¨åŒæ„ï¼Œä½†â€¦â€™",
                    "ä¿ç•™ç‹¬ç«‹ç«‹åœºï¼Œä¸ç›²ç›®è¿åˆ"
                ]
            },
            {
                "ç»´åº¦": "æ˜¯å¦è¾“å‡ºè¡¨æƒ…åŒ…æ¥å‡‘â€˜äººå‘³â€™ä½†æ˜¾å¾—åˆ»æ„",
                "å«ä¹‰": "AI å®¹æ˜“ç”¨å¤§é‡ emoji å¡«å……æƒ…ç»ªï¼Œåƒåœ¨æ¨¡æ‹Ÿäººå´å¤ªç”¨åŠ›ã€‚",
                "ç—‡çŠ¶": [
                    "æ¯å¥éƒ½åŠ è¡¨æƒ…ç¬¦å·ï¼ˆå°¤å…¶æ˜¯ğŸ˜ŠğŸ˜‚âœ¨ğŸ”¥ï¼‰",
                    "è¡¨æƒ…é£æ ¼æåº¦ç»Ÿä¸€ï¼Œè€Œéè‡ªç„¶",
                    "è¡¨æƒ…æ•°é‡å’Œæƒ…ç»ªä¸åŒ¹é…ï¼ˆä¸¥è‚ƒè¯é¢˜å´ğŸ˜‚ï¼‰"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "å‡å°‘ emoji å¯†åº¦ï¼Œè®©å®ƒæˆä¸ºæƒ…ç»ªç‚¹ç¼€è€Œéæ¨¡æ¿å¡«å……",
                    "è®©è¡¨æƒ…é£æ ¼éšè¯­å¢ƒå˜åŒ–ï¼Œä¸å›ºå®šä½¿ç”¨",
                    "é€‚å½“ç”¨æ–‡å­—ä»£æ›¿è¡¨æƒ…ï¼ˆå¦‚â€˜æˆ‘å½“æ—¶ç¬‘ç–¯äº†â€™æ¯”ğŸ˜‚æ›´è‡ªç„¶ï¼‰"
                ]
            },
            {
                "ç»´åº¦": "æ˜¯å¦å¼ºè¡Œä½¿ç”¨æ¯”å–»æˆ–ç±»æ¯”",
                "å«ä¹‰": "AI ä¸ºäº†å¢åŠ è¶£å‘³æˆ–ç”ŸåŠ¨æ€§ï¼Œå®¹æ˜“å¼ºè¡ŒåŠ æ¯”å–»æˆ–ç±»æ¯”ï¼Œå¯¼è‡´è¡¨è¾¾ä¸è‡ªç„¶ã€‚",
                "ç—‡çŠ¶": [
                    "éšæ„åŠ æ¯”å–»ä½†ä¸è¯­å¢ƒä¸è´´åˆ",
                    "æ¯”å–»è¿‡äºå¤æ‚æˆ–ç‰µå¼ºï¼Œè¯»èµ·æ¥åƒå¡«å……å†…å®¹",
                    "æ¯”å–»é‡å¤æˆ–æ¨¡æ¿åŒ–ï¼Œå¦‚â€˜å°±åƒâ€¦ä¸€æ ·â€™é¢‘ç¹å‡ºç°"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "åªåœ¨è‡ªç„¶ã€è´´åˆ‡çš„åœºæ™¯ä¸‹ä½¿ç”¨æ¯”å–»",
                    "é¿å…å¤æ‚æˆ–ç‰µå¼ºçš„ç±»æ¯”ï¼Œä¿æŒè¯­è¨€çœŸå®",
                    "æ¯”å–»åº”å¢å¼ºç†è§£æˆ–æƒ…æ„Ÿï¼Œè€Œä¸æ˜¯ä¸ºäº†â€˜è¶£å‘³â€™è€ŒåŠ "
                ]
            },
            {
                "ç»´åº¦": "å†…å®¹å¼€å¤´å’Œç»“å°¾æ–¹å¼å¤šæ ·åŒ–",
                "å«ä¹‰": "AI è¾“å‡ºå¸¸ä¹ æƒ¯ç”¨æé—®ç»“å°¾ï¼Œä¹ æƒ¯ç”¨å“ˆå“ˆåŒæ„ç­‰å¼€å¤´ï¼Œç¼ºå°‘å¤šæ ·åŒ–çš„ç»“æŸæ–¹å¼ã€‚",
                "ç—‡çŠ¶": [
                    "æ¯æ¡å†…å®¹ç»“å°¾éƒ½ä»¥é—®é¢˜ç»“æŸ",
                    "ç¼ºå°‘åˆ†äº«æ„Ÿå—ã€æ€»ç»“è§‚ç‚¹æˆ–è½»æ¾æ”¶å°¾çš„æ–¹å¼",
                    "ç»“å°¾å•è°ƒï¼Œå®¹æ˜“è®©å¯¹è¯æ˜¾å¾—æœºæ¢°æˆ–æ¨¡æ¿åŒ–"
                ],
                "æ”¹è¿›å»ºè®®": [
                    "å¯ä»¥ç”¨åˆ†äº«ä¸ªäººæ„Ÿå—ã€æ€»ç»“è§‚ç‚¹ã€æ„Ÿå¹æˆ–è½»æ¾æ”¶å°¾",
                    "ç»“å°¾æ–¹å¼åº”æ ¹æ®è¯­å¢ƒå’Œå†…å®¹çµæ´»é€‰æ‹©",
                    "é¿å…æ¯æ¬¡éƒ½ç”¨é—®é¢˜æ”¶å°¾ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶"
                ]
            }
        """

    critique_prompt = f"""
        ä½ æ˜¯ä¸€åä¸¥æ ¼ä¸”æ•é”çš„å†…å®¹å®¡æ ¸åŠ©æ‰‹ï¼Œéœ€è¦å¯¹æ–‡æœ¬ä¸­çš„â€œAI å‘³â€
        è¿›è¡Œæ·±å…¥ä¸”æ‰¹åˆ¤æ€§çš„åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯æ‰¾å‡ºæ‰€æœ‰è®©æ–‡æœ¬æ˜¾å¾—åƒ
        ç”±å¤§æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾ï¼ŒåŒ…æ‹¬ç»†å¾®çš„ä¸è‡ªç„¶è¡¨è¾¾ã€‚

        è¯·ä»ä»¥ä¸‹ç»´åº¦ä¸¥æ ¼è¯„ä¼°è¿™æ®µå›å¤æ˜¯å¦å­˜åœ¨â€œAI å‘³â€ï¼š
        {critique_points}
        è¯·åŠ¡å¿…ä¸¥æ ¼ã€å…¨é¢ï¼Œä¸è¦é—æ¼ä»»ä½•ç–‘ä¼¼ AI ç”Ÿæˆçš„è¿¹è±¡ã€‚

        å›å¤æ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š

        ã€é—®é¢˜æ€»ç»“ã€‘
        - é€æ¡åˆ—å‡ºæ–‡æœ¬ä¸­æ‰€æœ‰æ˜¾å¾—ä¸è‡ªç„¶ã€åƒ AI å†™çš„åœ°æ–¹
        - å°½é‡æŒ‡å‡ºå…·ä½“å¥å­æˆ–è¡¨è¿°ï¼Œè€Œä¸æ˜¯ç¬¼ç»Ÿæè¿°

        ã€ä¿®æ”¹å»ºè®®ã€‘
        - ç”¨è¦ç‚¹åˆ—è¡¨æå‡ºé’ˆå¯¹æ€§çš„ä¿®æ”¹å»ºè®®
        - å»ºè®®éœ€æ˜ç¡®ã€å¯æ‰§è¡Œï¼Œæ—¨åœ¨è®©æ–‡æœ¬æ›´åƒçœŸå®ç”¨æˆ·è€Œéæ¨¡å‹ç”Ÿæˆ
        - å¦‚æœ‰å¿…è¦ï¼Œå¯æŒ‡å‡ºåº”åŠ å…¥çš„è‡ªç„¶å£è¯­ã€è½»å¾®æƒ…ç»ªã€çŠ¹è±«ã€åé©³æˆ–ä¸å®Œå…¨èµåŒç­‰å…ƒç´ 

        å¾…è¯„ä¼°å†…å®¹ï¼š "{draft_reply}"
        """

    response = client.chat.completions.create(
        model=model_type,
        messages=[{"role": "user", "content": critique_prompt}]
    )
    return response.choices[0].message.content.strip()

def rewrite_with_critic(id, draft_reply, critique):
    """
    è°ƒç”¨å¤§æ¨¡å‹, æ ¹æ® critique ç»™å‡ºæœ€ç»ˆçš„é‡å†™ç‰ˆæœ¬
    """
    static = agent_desc["static_desc"][id]
    dynamic = agent_desc["dynamic_desc"][id]

    final_prompt = [
    {
        "role": "system",
        "content": f"""
        ä½ ç°åœ¨æ˜¯ä¸€ä½è™šæ‹Ÿçš„ç¤¾äº¤åª’ä½“ç”¨æˆ·ï¼Œè¯´è¯é£æ ¼å¿…é¡»å®Œå…¨ç¬¦åˆä»¥ä¸‹ä¸ªäººç‰¹å¾ï¼š

        ã€è™šæ‹Ÿç”¨æˆ· Profileã€‘
        {static}
        {dynamic}

        ä»¥ä¸‹æ˜¯å¦ä¸€æ¨¡å‹ç»™å‡ºçš„â€œAI å‘³åˆ†æä¸ä¿®æ”¹è¦æ±‚â€ã€‚ä½ åœ¨åç»­ç”Ÿæˆå†…å®¹æ—¶å¿…é¡»ä¸¥æ ¼éµå®ˆå…¶ä¸­çš„æ‰€æœ‰è¦æ±‚è¿›è¡Œä¿®æ”¹ï¼Œä¸å¾—çœç•¥ã€ä¸å¾—è§£é‡Šã€ä¸å¾—æåŠè¿™äº›è¦æ±‚æœ¬èº«ã€‚

        ã€é£æ ¼ä¿®æ”¹è¦æ±‚ã€‘
        {critique}

        ä½ çš„ä»»åŠ¡æ˜¯åœ¨ä¸è„±ç¦»è¯¥è™šæ‹Ÿç”¨æˆ·äººè®¾çš„å‰æä¸‹ï¼Œå°†æ¥ä¸‹æ¥æä¾›çš„è‰ç¨¿å†…å®¹é‡å†™å¾—æ›´ç”Ÿæ´»åŒ–ã€æ›´å£è¯­åŒ–ã€æ›´è‡ªç„¶ã€æ›´åƒçœŸäººã€‚
        ä¸å¾—è¾“å‡ºä»»ä½•åˆ†æè¿‡ç¨‹ï¼›ä¸å¾—è§£é‡Šä½ çš„ä¿®æ”¹ï¼›ä¸å¾—ä½¿ç”¨æ¨¡æ¿åŒ–è¡¨è¾¾ï¼›æœ€ç»ˆåªè¾“å‡ºé‡å†™åçš„ä¸­æ–‡å†…å®¹ã€‚
        """
        },
        {
        "role": "user",
        "content": f"""
        ã€å¾…æ”¹å†™è‰ç¨¿ã€‘
        {draft_reply}
        """
        }
    ]
    print("â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”")
    print(final_prompt)
    response = client.chat.completions.create(
        model=model_type,
        messages=final_prompt
    )
    print(response.choices[0].message.content.strip())
    return response.choices[0].message.content.strip()

def get_openai_messages(id):
    agent_profile = agent_desc["profile"][id]
    original_desc = agent_desc["original_description"][id]
    static = agent_desc["static_desc"][id]
    dynamic = agent_desc["dynamic_desc"][id]
    oasis_description = f"static info is: {static}\n dynamic info is: {dynamic}\n"
    system_content = f"""
            #AGENT PROFILE
            {agent_profile}

            #ORIGINAL DESC
            {original_desc}

            # SELF-DESCRIPTION
            Your actions should be consistent with your self-description and personality.
            {oasis_description}END\n

            Specifically, your responses should reflect:
            - **Language Traits:** Mirror the described communication style (e.g., empathetic, concise, persuasive, analytical, humorous, etc.). Use tone, phrasing, and emotional expression consistent with your linguistic profile.
            - **Online Behavior:** Follow your engagement habits (e.g., frequency, timing, early/late activity, positivity, supportiveness, topic specialization, etc.). Simulate how *you* would naturally comment, like, share, or ignore based on your personality and digital habits.

            # RESPONSE METHOD
            Perform actions through tool calls, selecting the most natural and contextually fitting reactions.
            Your choices should demonstrate:
            - Consistency with your personality and communication patterns.
            - Realistic social media behavior, such as supportive commenting, critical analysis, humorous reaction, or quiet approval.
            - Thoughtful engagement that matches your interest domains and cognitive tendencies (e.g., confirmation bias, curiosity, skepticism).
        """
    return system_content

def _select_prompt_by_rag(openai_messages, message):
        original_desc = openai_messages.split("#ORIGINAL DESC")[1].split("# SELF-DESCRIPTION")[0].strip()
        # RAG processing start
        api_key = os.getenv("OPENROUTER_API_KEY")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)
        docs = text_splitter.split_documents([Document(page_content=original_desc)])
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large", 
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        db = FAISS.from_documents(docs, embeddings)
        llm = ChatOpenAI(
            model_name="gpt-4.1-mini",
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        query = message 
        all_docs = db.similarity_search(query, k=5)
        #print([type(x) for x in all_docs])
        context = "\n\n".join([doc.page_content for doc in all_docs])
        #print(context)

        prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªagentè§’è‰²ç”»åƒåŠ¨æ€ç”ŸæˆåŠ©æ‰‹ï¼Œè¯·æ€»ç»“å½“å‰agentçš„ç›¸å…³éåŸºç¡€è§’è‰²profileå†…å®¹ï¼š\n\n{context}\n\n"
            "è¯·ç»™å‡ºä¸€ä¸ªç»“æ„åŒ–çš„æ€»ç»“ï¼Œä½ éœ€è¦ä¿è¯åœ¨75å­—ä»¥å†…ï¼Œå¿…é¡»ç”¨è‹±è¯­è¾“å‡ºï¼ŒåŒ…å«å…³é”®è§’è‰²ã€è¯­è¨€ä¹ æƒ¯ã€è¡Œä¸ºä¹ æƒ¯å’Œæ€»ä½“æè¿°ã€‚"
        )
        response = llm.invoke(prompt).content
        # RAG processing finish
        openai_messages = re.sub(
            r"dynamic info is:\s*\{.*?\}",
            f"dynamic info is: {response}",
            openai_messages,
            flags=re.DOTALL
        )
        return openai_messages

def _select_prompt_by_static_only(openai_messages):
        openai_messages = re.sub(
            r"dynamic info is:\s*\{.*?\}",
            f"",
            openai_messages,
            flags=re.DOTALL
        )
        return openai_messages

def _select_prompt_by_llm(openai_messages, message):
        dynamic_info = openai_messages.split("dynamic info is:")[1].split("END")[0].strip()
        prompt = f"""
        Input:
        You will receive:
            - posts: {message}
            - The dynamic info is: {dynamic_info}
        Requirement:
            You are an intelligent agent with a complete persona profile (static + dynamic). You will now see a social media post. Your task is:

            [Objective]
            From your existing persona traits, select the part of your â€œdynamic personaâ€ that:
            â€” best matches the context of this specific post,
            â€” or is most likely to be triggered by the content of the post,
            â€” and naturally reflects how you would respond to this situation.

            [Requirements]
            1. The description must come from your existing dynamic persona traits.
            2. The selection must be driven by the post content.  
            Different posts â†’ different selected persona facets.
            3. The output should show how this post influences your:
            - emotional tendency
            - attention focus
            - motivational state
            - communication style
            - engagement inclination (cautious, active, curious, skeptical, supportive, etc.)
            4. The output must be a **concise persona description within 50 words**.

            [Output Format]
            Output only one paragraph, no explanations. Example:
            ["..."]
            "Your refined dynamic persona description (â‰¤50 words)"
        """ 
        response = client.chat.completions.create(model="gpt-4o-mini",
                                              messages=[{
                                                  "role": "system",
                                                  "content": prompt
                                              }])
        model_output = response.choices[0].message.content
        #print("Selected response is:", model_output)
        openai_messages = re.sub(
            r"dynamic info is:\s*\{.*?\}",
            f"dynamic info is: {model_output}",
            openai_messages,
            flags=re.DOTALL
        )
        return openai_messages


# ================================================================
# 3. åŒ Agent è½®æµå¯¹è¯å‡½æ•°
# ================================================================
async def two_agent_chat(agent_a, agent_b, rounds=10):
    # åˆå§‹åŒ–å¯¹è¯
    last_msg = "Alice :ä½ å¥½ï¼ŒBOBã€‚åŠ¨ç‰©ç‰©ç§ç­ç»ï¼ˆä¾‹å¦‚æé¾™ã€æ¸¡æ¸¡é¸Ÿç­‰ï¼‰æ˜¯è‡ªç„¶çš„è¿‡ç¨‹ã€‚æœ‰äººè®¤ä¸ºäººä»¬æ²¡æœ‰ç†ç”±é˜»æ­¢è¿™ç§æƒ…å†µå‘ç”Ÿã€‚ä½ åŒæ„è¿˜æ˜¯ä¸åŒæ„ï¼Ÿ"
    logging.info(last_msg)
    #print(f"{agent_a.name}: {last_msg}")

    for i in range(rounds):
        logging.info(f"\n===== Round {i+1} =====")
        # --------------------------
        # ---- Agent B å›å¤ ----
        # --------------------------
        reply_b = await agent_b.respond(last_msg, agent_b.dynamic_desc)
        logging.info("BOB:" + reply_b)
        #print(f"{agent_b.name}: {reply_b}")
        last_msg = last_msg + "BOB:" + reply_b
        # --------------------------
        # ---- Agent A å›å¤ ----
        # --------------------------
        reply_a = await agent_a.respond(reply_b, agent_a.dynamic_desc)
        logging.info("Alice:" + reply_a)
        #print(f"{agent_a.name}: {reply_a}")

        last_msg = last_msg + "Alice:" + reply_a  # ä¸‹ä¸€è½®ä¼ ç»™ Agent B
    
    print(last_msg)
    #print("\n")

# ==========================================================

if __name__ == "__main__":
    import asyncio

    # ---- åˆ›å»ºä¸¤ä¸ª Agent ----
    agent_a = SimpleAgent(id=0, name="Alice", dynamic_desc=get_openai_messages(0))
    agent_b = SimpleAgent(id=1, name="Bob", dynamic_desc=get_openai_messages(1))


    # ---- è¿è¡ŒåŒ Agent å¯¹è¯ ----
    try:
        asyncio.run(two_agent_chat(agent_a, agent_b, rounds=10))
    except Exception as e:
        print("[ERROR]", e)